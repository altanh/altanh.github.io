Hello! I'm currently a Computer Science PhD student at UC Berkeley supervised
by [Max Willsey](https://mwillsey.com). **After Spring 2025, I will be taking a
leave of absence to explore exciting industry opportunities. If you think I
might be a good fit, please reach out!**

During my PhD, I broadly focused on compilers and optimizations for high
performance code. This included [optimizing sparse matrix multiplication
algorithms on NUMA shared-memory
systems](https://ieeexplore.ieee.org/document/10596518), bridging techniques
between sparse computing and database query optimization, as well as
experimenting with [e-graphs](https://egraphs.org/) for rewriting SSA-based
intermediate representations.

In the past, I've worked on [memory optimizations for deep learning
training](https://arxiv.org/abs/2006.09616), as well as more general
compilation techniques for machine learning via [TVM](https://tvm.apache.org/)
(at OctoML, which was eventually acquired by NVIDIA).

I remain excited about the opportunities that optimizing compilation offer, and
hope to apply my experience to industrial use-cases.

## Links

- [GitHub](https://github.com/altanh)
- [LinkedIn](https://www.linkedin.com/in/altanh/)
- [Twitter/X](https://x.com/altan0)

